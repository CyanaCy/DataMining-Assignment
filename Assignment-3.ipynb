{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assighment #3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Yi Chen<br/>ID: 1001778238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from random import seed, randrange\n",
    "from math import log\n",
    "\n",
    "NEG = 0\n",
    "POS = 1\n",
    "ALL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(str):\n",
    "    str=str.replace('<br />', '')\n",
    "    lst = re.sub('[^0-9a-zA-Z]', ' ', str).split()\n",
    "    return set([x.lower() for x in lst if x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address=['aclImdb\\\\train\\\\neg\\\\',  'aclImdb\\\\train\\\\pos\\\\', 'aclImdb\\\\test\\\\neg\\\\', 'aclImdb\\\\test\\\\pos\\\\']\n",
    "files=[os.listdir(x) for x in address]\n",
    "\n",
    "train_neg, train_pos = [], []\n",
    "test_neg, test_pos = [], []\n",
    "data = [train_neg, train_pos, test_neg, test_pos]\n",
    "label = [0, 1, 0, 1] # 0: neg  1: pos\n",
    "\n",
    "for i in range(len(address)):\n",
    "    for file_name in files[i]:\n",
    "        words = set()\n",
    "        f=open(address[i]+file_name,'r',encoding='utf8')\n",
    "        lines=f.readlines()\n",
    "        for line in lines:\n",
    "            words = words.union(segmentation(line))\n",
    "        data[i].append([words,label[i]])\n",
    "\n",
    "train = train_neg + train_pos\n",
    "test = test_neg + test_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Divide the dataset as train, development and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In train set, randomly select 75% of the reviews as training set and 25% as development set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set:  18750\n",
      "Size of development set:  6250\n",
      "Size of test set:  25000\n"
     ]
    }
   ],
   "source": [
    "dev=[]\n",
    "\n",
    "dev_size = int(len(train)*0.25)\n",
    "\n",
    "seed(1)\n",
    "\n",
    "for _ in range(dev_size):\n",
    "    random_index = randrange(len(train))\n",
    "    dev.append(train.pop(random_index))\n",
    "\n",
    "print('Size of train set: ', len(train))\n",
    "print('Size of development set: ', len(dev))\n",
    "print('Size of test set: ', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(data, occurrence_threshold):\n",
    "    voca = {} #{'word':[neg_count, pos_count, all_count]}\n",
    "    \n",
    "    for rev in data:\n",
    "        for word in rev[0]:\n",
    "            if word not in voca:\n",
    "                voca[word] = [0,0,1]\n",
    "            else:\n",
    "                voca[word][ALL]+=1\n",
    "            voca[word][rev[1]] += 1\n",
    "    for key in list(voca.keys()):\n",
    "        if voca[key][ALL]<occurrence_threshold:\n",
    "            del voca[key]\n",
    "    return voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_voca = build_vocabulary(train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Calculate the following probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label(data):\n",
    "    label_count=[0,0, len(data)] # [neg_count, pos_count, all_count]\n",
    "    for item in data:\n",
    "        if item[1]==NEG:\n",
    "            label_count[NEG]+=1\n",
    "        else:\n",
    "            label_count[POS]+=1\n",
    "    return label_count\n",
    "        \n",
    "def cal_occurrence_probability(word, vocabulary, label_count):\n",
    "    word = word.lower()\n",
    "    if word not in vocabulary:\n",
    "        return 0\n",
    "    return vocabulary[word][ALL]/label_count[ALL]\n",
    "\n",
    "def cal_conditional_probability(word, vocabulary, label_count, label): \n",
    "    word = word.lower()\n",
    "    if word not in vocabulary:\n",
    "        return 0\n",
    "    return vocabulary[word][label]/label_count[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P[\"the\"] =  0.9911466666666666\n",
      "P[\"the\"|Positive] =  0.9900683468603161\n"
     ]
    }
   ],
   "source": [
    "label_count_train = count_label(train)\n",
    "print('P[\"the\"] = ', cal_occurrence_probability('the', train_voca, label_count_train))\n",
    "print('P[\"the\"|Positive] = ', cal_conditional_probability('the', train_voca, label_count_train, POS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## d. Calculate accuracy using dev dataset (five fold cross validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review, vocabulary, label_count, lam):\n",
    "    probability = []\n",
    "    for label in [NEG, POS]:\n",
    "        prob = log(label_count[label]/label_count[ALL])\n",
    "        for word in review[0]:\n",
    "            if word not in vocabulary:\n",
    "                continue\n",
    "            if lam == 0 and vocabulary[word][label]==0:\n",
    "                prob = 0\n",
    "                break\n",
    "            prob += log((vocabulary[word][label]+lam) / (label_count[label]+lam*len(vocabulary)))\n",
    "        probability.append(prob)\n",
    "    \n",
    "    return NEG if probability[NEG]>probability[POS] else POS\n",
    "\n",
    "def cal_k_fold_accuracy(data, lam, k, occurrence_shreshold):\n",
    "    accuracy = []\n",
    "\n",
    "    folds=[]\n",
    "    fold_size=len(data)//k\n",
    "    data = list(data) \n",
    "    for _ in range(k):\n",
    "        fold=[]\n",
    "        for _ in range(fold_size):\n",
    "            random_index=randrange(len(data))\n",
    "            fold.append(data.pop(random_index))\n",
    "        folds.append(fold)\n",
    "        \n",
    "    for fold in folds:\n",
    "        train_fold = list(folds)\n",
    "        train_fold.remove(fold)\n",
    "        train_fold = sum(train_fold, [])\n",
    "        test_fold = fold\n",
    "        \n",
    "        voca = build_vocabulary(train_fold, occurrence_shreshold)\n",
    "        label_count = count_label(train_fold)\n",
    "        correct = 0\n",
    "        for review in test_fold:\n",
    "            if predict(review, voca, label_count, lam) == review[1]:\n",
    "                correct+=1\n",
    "        accuracy.append(correct/len(test_fold))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-folds accuracy:  [0.6144, 0.652, 0.6208, 0.6296, 0.6352]\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "\n",
    "accuracy_without_smoothing_dev = cal_k_fold_accuracy(dev, 0, 5, 5)\n",
    "print('5-folds accuracy: ', accuracy_without_smoothing_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e. Do following experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the effect of Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy(train_set, test_set, lam, occurrence_shreshold):\n",
    "    voca = build_vocabulary(train_set, occurrence_shreshold)\n",
    "    label_count = count_label(train_set)\n",
    "    correct = 0\n",
    "    for review in test_set:\n",
    "        if predict(review, voca, label_count, lam) == review[1]:\n",
    "            correct+=1\n",
    "    return correct/len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy when not using Smoothing:  0.67088\n",
      "Accuracy when using Laplace Estimate:  0.85136\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy when not using Smoothing: \", cal_accuracy(train, dev, 0, 5))\n",
    "print(\"Accuracy when using Laplace Estimate: \", cal_accuracy(train, dev, 1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derive Top 10 words that predict positive and negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_10(data, occurrence_shreshold):\n",
    "    vocabulary = build_vocabulary(data, occurrence_shreshold)\n",
    "    label_count = count_label(data)\n",
    "    \n",
    "    word_predict = {}\n",
    "    \n",
    "    for review in data:\n",
    "        for word in review[0]:\n",
    "            if word not in vocabulary: continue\n",
    "            neg_prob = cal_conditional_probability(word, vocabulary, label_count, NEG) * label_count[NEG]/label_count[ALL] \\\n",
    "                         / cal_occurrence_probability(word, vocabulary, label_count) if vocabulary[word][NEG] > 0 else 0\n",
    "            pos_prob = cal_conditional_probability(word, vocabulary, label_count, POS) * label_count[POS]/label_count[ALL] \\\n",
    "                        / cal_occurrence_probability(word, vocabulary, label_count)  if vocabulary[word][POS] > 0 else 0\n",
    "            pred = NEG if neg_prob > pos_prob else POS\n",
    "            if word not in word_predict:\n",
    "                word_predict[word] = [0,0,0]\n",
    "            word_predict[word][ALL] += 1\n",
    "            if pred == review[1]:       \n",
    "                word_predict[word][pred] += 1\n",
    "        \n",
    "    top_neg_lst = sorted(word_predict, key = lambda x: word_predict[x][NEG]/word_predict[x][ALL], reverse=True) [:10]\n",
    "    top_pos_lst = sorted(word_predict, key = lambda x: word_predict[x][POS]/word_predict[x][ALL], reverse=True)[:10]\n",
    "    \n",
    "    return top_neg_lst, top_pos_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 words that predict negative class:  ['gamers', 'incessant', 'humorless', 'keyboard', 'turd', 'mohanlal', 'nisha', 'bachchan', 'kothari', 'sholay']\n",
      "Top 10 words that predict positive class:  ['din', 'mclaglen', 'fairbanks', 'audiard', 'sunrise', 'tempest', 'finely', 'rory', 'malone', 'sirk']\n"
     ]
    }
   ],
   "source": [
    "top_neg_lst, top_pos_lst = get_top_10(dev, 5)\n",
    "print(\"Top 10 words that predict negative class: \", top_neg_lst)\n",
    "print(\"Top 10 words that predict positive class: \", top_pos_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## f. Using the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy:  0.83444\n"
     ]
    }
   ],
   "source": [
    "final_accuracy_test = cal_accuracy(train, test, 1, 5) #lambda = 1, occurrence_shreshold = 5\n",
    "print(\"Final Accuracy: \", final_accuracy_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
